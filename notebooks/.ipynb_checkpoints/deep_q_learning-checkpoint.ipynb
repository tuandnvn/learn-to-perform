{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "# Wrappers are used to transform an environment in a modular way\n",
    "# It is just to add extensional functionalities\n",
    "# Monitor: That could help to record a video on an episode!\n",
    "# That is really nice!!!!\n",
    "from gym.wrappers import Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import random \n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "import plotting\n",
    "from collections import deque, namedtuple\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.envs.make(\"Breakout-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atari Actions: 0 (noop), 1 (fire), 2 (left) and 3 (right) are valid actions\n",
    "VALID_ACTIONS = [0, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space size: 4\n",
      "['NOOP', 'FIRE', 'RIGHT', 'LEFT']\n",
      "Observation space shape: (210, 160, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANEAAAD8CAYAAADpCEEHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11666ee48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANEAAAD8CAYAAADpCEEHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAADnxJREFUeJzt3X/sVfV9x/Hna1hNRruA9UcM4ABH\n2+myfWuJI3Oabq4WSVN0STvIUtlmhiaStNElw5psZkmTrauYNNtoMJLiYlE3aiWLtRDW1CwbVrCI\nUESB0voVAlMXcdjUAe/9cT7f9Prle/le7vvc3nMvr0dyc+/93HPPeZ/Ai8+5h3PfVxGBmXXvl/pd\ngNmgc4jMkhwisySHyCzJITJLcojMknoWIkkLJe2VtE/Syl5tx6zf1Iv/J5I0BXgZ+AQwCjwHLI2I\nH9a+MbM+69VMdA2wLyIORMS7wKPA4h5ty6yvzuvRemcAr7Y8HwV+u93CknzZhDXR6xFx8WQL9SpE\nmmDsPUGRtBxY3qPtm9Xhx50s1KsQjQKzWp7PBA61LhARa4A14JnIBluvPhM9B8yTNEfS+cASYGOP\ntmXWVz2ZiSLihKQVwHeAKcDaiNjdi22Z9VtPTnGfdRENPJxbtWrVWb/nrrvuSq1j/PvrWkdWE2oY\nb3xNPdrm9oiYP9lCvmLBLKlXJxaGTi9miX7MdnX4Rcw0g8QzkVmSZyI7a5PNfufaTOWZyCzJM5FN\narKZpR+fy5rEM5FZkmeiDtXxr21T1jEI2xwknonMkhwisyRf9mPWni/7MftFaMSJhZkzZ55z/0Fn\nzdfp30nPRGZJDpFZkkNkluQQmSV1HSJJsyR9V9IeSbslfb6M3yfpNUk7ym1RfeWaNU/m7NwJ4O6I\neF7SB4DtkjaX1x6IiK/kyzNrvq5DFBGHgcPl8duS9lA1bTQ7p9TymUjSbOCjwLNlaIWknZLWSppe\nxzbMmiodIknvBzYAX4iIY8Bq4ApghGqmur/N+5ZL2iZp2/Hjx7NlmPVNKkSS3kcVoEci4psAEXEk\nIk5GxCngQarm9qeJiDURMT8i5k+dOjVThllfZc7OCXgI2BMRq1rGL2tZ7BZgV/flmTVf5uzctcDn\ngBcl7ShjXwSWShqhamB/ELg9VaFZw2XOzv0HE//6w1Pdl2M2eHzFgllSI74KMRl/TcJ6oa7eEZ6J\nzJIcIrMkh8gsySEyS3KIzJIcIrMkh8gsySEyS3KIzJIcIrMkh8gsySEyS3KIzJIcIrMkh8gsKf19\nIkkHgbeBk8CJiJgv6ULgMWA21VfEPxsR/5PdllkT1TUT/V5EjLT8qthKYEtEzAO2lOdmQ6lXh3OL\ngXXl8Trg5h5tx6zv6ghRAJskbZe0vIxdWtoMj7UbvqSG7Zg1Uh09Fq6NiEOSLgE2S3qpkzeVwC0H\nmD7dnYZtcKVnoog4VO6PAk9QdTw9MtbEsdwfneB97oBqQyHbRnhq+VkVJE0FbqTqeLoRWFYWWwY8\nmdmOWZNlD+cuBZ6oOgpzHvCNiHha0nPA45JuA34CfCa5HbPGSoUoIg4AvzXB+BvADZl1mw0KX7Fg\nljQQHVC3LlzY7xJsCP1nTevxTGSW5BCZJTlEZkkOkVmSQ2SWNBBn50792rF+l2DWlmcisySHyCzJ\nITJLcojMkhwisySHyCxpIE5xv/kr7/S7BLO2PBOZJTlEZkldH85J+jBVl9Mxc4G/AqYBfw78dxn/\nYkQ81XWFZg3XdYgiYi8wAiBpCvAaVbefPwUeiIiv1FKhWcPVdTh3A7A/In5c0/rMBkZdZ+eWAOtb\nnq+QdCuwDbg728z+zY+8m3m72cRer2c16ZlI0vnAp4F/KUOrgSuoDvUOA/e3ed9ySdskbTt+/Hi2\nDLO+qeNw7ibg+Yg4AhARRyLiZEScAh6k6oh6GndAtWFRR4iW0nIoN9Y+uLiFqiOq2dBKfSaS9MvA\nJ4DbW4a/LGmE6tciDo57zWzoZDugvgN8cNzY51IVmQ2Ygbh27hunLu93CTaEbqxpPb7sxyzJITJL\ncojMkhwisySHyCxpIM7Ovfvoff0uwYbRjfX8uIpnIrMkh8gsySEyS3KIzJIcIrMkh8gsaSBOcf/7\n0wv6XYINoU/duKqW9XgmMktyiMySHCKzpI5CJGmtpKOSdrWMXShps6RXyv30Mi5JX5W0T9JOSVf3\nqnizJuh0Jvo6sHDc2EpgS0TMA7aU51B1/5lXbsupWmiZDa2OQhQRzwBvjhteDKwrj9cBN7eMPxyV\nrcC0cR2AzIZK5jPRpRFxGKDcX1LGZwCvtiw3Wsbew80bbVj04sSCJhiL0wbcvNGGRCZER8YO08r9\n0TI+CsxqWW4mcCixHbNGy4RoI7CsPF4GPNkyfms5S7cAeGvssM9sGHV02Y+k9cDHgYskjQJ/Dfwt\n8Lik24CfAJ8piz8FLAL2Ae9Q/V6R2dDqKEQRsbTNSzdMsGwAd2aKMhskvmLBLMkhMktyiMySHCKz\nJIfILMkhMktyiMySHCKzJIfILMkhMktyiMySHCKzJIfILMkhMktyiMySHCKzJIfILGnSELXpfvr3\nkl4qHU6fkDStjM+W9FNJO8rta70s3qwJOpmJvs7p3U83A78REb8JvAzc0/La/ogYKbc76inTrLkm\nDdFE3U8jYlNEnChPt1K1xTI7J9XxmejPgG+3PJ8j6QeSvifpunZvcgdUGxapX8qTdC9wAnikDB0G\nLo+INyR9DPiWpKsi4tj490bEGmANwKxZs07rkGo2KLqeiSQtAz4F/HFpk0VE/Cwi3iiPtwP7gQ/V\nUahZU3UVIkkLgb8EPh0R77SMXyxpSnk8l+rnVQ7UUahZU016ONem++k9wAXAZkkAW8uZuOuBv5F0\nAjgJ3BER43+SxWyoTBqiNt1PH2qz7AZgQ7Yos0HiKxbMkhwisySHyCzJITJLcojMkhwisySHyCzJ\nITJLcojMkhwisySHyCzJITJLcojMkhwisySHyCzJITJLcojMkrrtgHqfpNdaOp0uanntHkn7JO2V\n9MleFW7WFN12QAV4oKXT6VMAkq4ElgBXlff801jjErNh1VUH1DNYDDxaWmf9CNgHXJOoz6zxMp+J\nVpSG9mslTS9jM4BXW5YZLWOncQdUGxbdhmg1cAUwQtX19P4yrgmWnbC7aUSsiYj5ETF/6tSpXZZh\n1n9dhSgijkTEyYg4BTzIzw/ZRoFZLYvOBA7lSjRrtm47oF7W8vQWYOzM3UZgiaQLJM2h6oD6/VyJ\nZs3WbQfUj0saoTpUOwjcDhARuyU9DvyQqtH9nRFxsjelmzVDrR1Qy/JfAr6UKcpskPiKBbMkh8gs\nySEyS3KIzJIcIrMkh8gsySEyS3KIzJIcIrMkh8gsySEyS3KIzJIcIrMkh8gsySEyS3KIzJK6bd74\nWEvjxoOSdpTx2ZJ+2vLa13pZvFkTTPrNVqrmjf8APDw2EBF/NPZY0v3AWy3L74+IkboKNGu6Tr4e\n/oyk2RO9JknAZ4Hfr7css8GR/Ux0HXAkIl5pGZsj6QeSvifpuuT6zRqvk8O5M1kKrG95fhi4PCLe\nkPQx4FuSroqIY+PfKGk5sBxg+vTp4182Gxhdz0SSzgP+EHhsbKz04H6jPN4O7Ac+NNH73QHVhkXm\ncO4PgJciYnRsQNLFY78CIWkuVfPGA7kSzZqtk1Pc64H/Aj4saVTSbeWlJbz3UA7gemCnpBeAfwXu\niIhOf1HCbCB127yRiPiTCcY2ABvyZZkNDl+xYJbkEJklOURmSQ6RWZJDZJbkEJklOURmSQ6RWZJD\nZJaUvYq7Fm9NOcW/TfvffpdhXdi6cGF6HQuefrqGSs7e72zaVMt6PBOZJTlEZkkOkVlSIz4T2eDq\n1+eZJvFMZJbkmcjOWXXNooqIWlaUKkLqfxFmp9seEfMnW6iTr4fPkvRdSXsk7Zb0+TJ+oaTNkl4p\n99PLuCR9VdI+STslXZ3fF7Pm6uQz0Qng7oj4dWABcKekK4GVwJaImAdsKc8BbqJqUDKPqiXW6tqr\nNmuQSUMUEYcj4vny+G1gDzADWAysK4utA24ujxcDD0dlKzBN0mW1V27WEGd1dq60E/4o8CxwaUQc\nhipowCVlsRnAqy1vGy1jZkOp47Nzkt5P1cnnCxFxrGrDPfGiE4ydduKgtQOq2SDraCaS9D6qAD0S\nEd8sw0fGDtPK/dEyPgrMann7TODQ+HW2dkDttnizJujk7JyAh4A9EbGq5aWNwLLyeBnwZMv4reUs\n3QLgrbHDPrOhFBFnvAG/S3U4thPYUW6LgA9SnZV7pdxfWJYX8I9UfbhfBOZ3sI3wzbcG3rZN9nc3\nIvyfrWZnUM9/tprZmTlEZkkOkVmSQ2SW5BCZJTXl+0SvA8fL/bC4iOHZn2HaF+h8f361k5U14hQ3\ngKRtw3T1wjDtzzDtC9S/Pz6cM0tyiMySmhSiNf0uoGbDtD/DtC9Q8/405jOR2aBq0kxkNpD6HiJJ\nCyXtLY1NVk7+juaRdFDSi5J2SNpWxiZs5NJEktZKOippV8vYwDaiabM/90l6rfwZ7ZC0qOW1e8r+\n7JX0ybPeYCeXevfqBkyh+srEXOB84AXgyn7W1OV+HAQuGjf2ZWBlebwS+Lt+13mG+q8HrgZ2TVY/\n1ddgvk31lZcFwLP9rr/D/bkP+IsJlr2y/L27AJhT/j5OOZvt9XsmugbYFxEHIuJd4FGqRifDoF0j\nl8aJiGeAN8cND2wjmjb7085i4NGI+FlE/AjYR/X3smP9DtGwNDUJYJOk7aV3BLRv5DIohrERzYpy\nCLq25fA6vT/9DlFHTU0GwLURcTVVz707JV3f74J6aFD/zFYDVwAjwGHg/jKe3p9+h6ijpiZNFxGH\nyv1R4Amqw4F2jVwGRaoRTdNExJGIOBkRp4AH+fkhW3p/+h2i54B5kuZIOh9YQtXoZGBImirpA2OP\ngRuBXbRv5DIohqoRzbjPbbdQ/RlBtT9LJF0gaQ5V597vn9XKG3AmZRHwMtVZkXv7XU8X9c+lOrvz\nArB7bB9o08iliTdgPdUhzv9R/ct8W7v66aIRTUP2559LvTtLcC5rWf7esj97gZvOdnu+YsEsqd+H\nc2YDzyEyS3KIzJIcIrMkh8gsySEyS3KIzJIcIrOk/weVy1jlrmZ17wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11667cb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print (env)\n",
    "# <TimeLimit<AtariEnv<Breakout-v0>>>\n",
    "# TimeLimit is env wrapper that provides ...\n",
    "# max_episode_seconds, max_episode_steps\n",
    "print(\"Action space size: {}\".format(env.action_space.n))\n",
    "print(env.env.get_action_meanings())\n",
    "\n",
    "observation = env.reset()\n",
    "print(\"Observation space shape: {}\".format(observation.shape))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(env.render(mode='rgb_array'))\n",
    "\n",
    "[env.step(2) for x in range(1)]\n",
    "plt.figure()\n",
    "plt.imshow(env.render(mode='rgb_array'))\n",
    "\n",
    "env.render(close=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateProcessor():\n",
    "    \"\"\"\n",
    "    Processes a raw Atari images. Resizes it and converts it to grayscale.\n",
    "    \n",
    "    It is a very interesting consideration to represent the whole system \n",
    "    as an image. It is understandable that the part corresponding to the \n",
    "    blocks should be represented like this, but \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        with tf.variable_scope(\"state_processor\"):\n",
    "            self.input_state = tf.placeholder(shape=[210, 160, 3], dtype=tf.uint8)\n",
    "            self.output = tf.image.rgb_to_grayscale(self.input_state)\n",
    "            # The upper part is not relevant (there is some score)\n",
    "            self.output = tf.image.crop_to_bounding_box(self.output, 34, 0, 160, 160)\n",
    "            \n",
    "            # Why resize from 160 to 84\n",
    "            self.output = tf.image.resize_images(\n",
    "                self.output, [84,84], \n",
    "                method = tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "            \n",
    "            self.output = tf.squeeze(self.output)\n",
    "            \n",
    "    def process(self, sess, state):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sess: a Tensorflow session object\n",
    "            state: A[210, 160, 3] Atari RGB state\n",
    "            \n",
    "        Returns:\n",
    "            A processed [84, 84, 1] state representing grayscale values\n",
    "        \"\"\"\n",
    "        return sess.run(self.output, {self.input_state: state})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Estimator():\n",
    "    \"\"\"\n",
    "    Q-Value Estimator neural network\n",
    "    \n",
    "    This network is used for both the Q-network and the Target Network\n",
    "    \"\"\"\n",
    "    def __init__(self, scope=\"estimator\", summaries_dir = None):\n",
    "        self.scope = scope\n",
    "        \n",
    "        # Write Tensorboard summaries to disk\n",
    "        self.summary_writer = None\n",
    "        with tf.variable_scope(scope):\n",
    "            self._build_model()\n",
    "            \n",
    "            if summaries_dir:\n",
    "                summary_dir = os.path.join(summaries_dir, \"summaries_{}\".format(scope))\n",
    "                if not os.path.exists(summary_dir):\n",
    "                    os.makedirs(summary_dir)\n",
    "                self.summary_writer = tf.summary.FileWriter(summary_dir)\n",
    "                \n",
    "    def _build_model(self):\n",
    "        \"\"\"\n",
    "        Builds the Tensorflow graph.\n",
    "        \n",
    "        Network calculate Q(s,a) - action value of (state, action)\n",
    "        \"\"\"\n",
    "        # Placeholders for our input\n",
    "        # Our input are 4 RGB frames of shape 160, 160 each\n",
    "        # Why 4?\n",
    "        self.X_pl = tf.placeholder(shape=[None, 84, 84, 4], dtype=tf.uint8, name=\"X\")\n",
    "        # target result of the network\n",
    "        self.y_pl = tf.placeholder(shape=[None],dtype=tf.uint8, name=\"y\")\n",
    "        \n",
    "        self.actions_pl = tf.placeholder(shape=[None], dtype=tf.int32, name=\"actions\")\n",
    "        \n",
    "        X = tf.to_float(self.X_pl) / 255.0\n",
    "        \n",
    "        batch_size = tf.shape(self.X_pl)[0]\n",
    "        \n",
    "        # This is a pretty big network\n",
    "        \n",
    "        # 64 filters of kernel size 8, stride of 4\n",
    "        # Size reduce to (84 - 8)/4 + 1 = (20, 20, 64)\n",
    "        conv1 = tf.contrib.layers.conv2d(X, 32, 8, 4, activation_fn = tf.nn.relu)\n",
    "        \n",
    "        # Size reduce to (20 - 4)/2 + 1 = (9, 9, 64)\n",
    "        conv2 = tf.contrib.layers.conv2d(X, 64, 4, 2, activation_fn = tf.nn.relu)\n",
    "        \n",
    "        # Size reduce to (9 - 3)/1 + 1 = (7, 7, 64)\n",
    "        conv3 = tf.contrib.layers.conv2d(X, 64, 3, 1, activation_fn = tf.nn.relu)\n",
    "        \n",
    "        # 7 * 7 * 64\n",
    "        flattened = tf.contrib.layers.flatten(conv3)\n",
    "        \n",
    "        fc1 = tf.contrib.layers.fully_connected(flattened, 512)\n",
    "        \n",
    "        self.predictions = tf.contrib.layers.fully_connected(fc1, len(VALID_ACTIONS))\n",
    "        \n",
    "        # Get the predictions for the chosen actions only\n",
    "        # Normally I would use the gather_2d function\n",
    "        gather_indices = tf.range(batch_size) * tf.shape(self.predictions)[1] + self.actions_pl\n",
    "        self.action_predictions = tf.gather(tf.reshape(self.predictions, [-1]), gather_indices)\n",
    "        \n",
    "        # Calcualte the loss\n",
    "        self.losses = tf.squared_difference(self.y_pl, self.action_predictions)\n",
    "        self.loss = tf.reduce_mean(self.losses)\n",
    "        \n",
    "        self.optimizer = tf.train.RMSPropOptimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
