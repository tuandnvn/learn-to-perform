{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import gym\n",
    "import itertools\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "\n",
    "\n",
    "from envs.cliff_walking import CliffWalkingEnv\n",
    "import plotting\n",
    "\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P': {0: {0: [(1.0, 0, -1.0, False)],\n",
       "   1: [(1.0, 1, -1.0, False)],\n",
       "   2: [(1.0, 12, -1.0, False)],\n",
       "   3: [(1.0, 0, -1.0, False)]},\n",
       "  1: {0: [(1.0, 1, -1.0, False)],\n",
       "   1: [(1.0, 2, -1.0, False)],\n",
       "   2: [(1.0, 13, -1.0, False)],\n",
       "   3: [(1.0, 0, -1.0, False)]},\n",
       "  2: {0: [(1.0, 2, -1.0, False)],\n",
       "   1: [(1.0, 3, -1.0, False)],\n",
       "   2: [(1.0, 14, -1.0, False)],\n",
       "   3: [(1.0, 1, -1.0, False)]},\n",
       "  3: {0: [(1.0, 3, -1.0, False)],\n",
       "   1: [(1.0, 4, -1.0, False)],\n",
       "   2: [(1.0, 15, -1.0, False)],\n",
       "   3: [(1.0, 2, -1.0, False)]},\n",
       "  4: {0: [(1.0, 4, -1.0, False)],\n",
       "   1: [(1.0, 5, -1.0, False)],\n",
       "   2: [(1.0, 16, -1.0, False)],\n",
       "   3: [(1.0, 3, -1.0, False)]},\n",
       "  5: {0: [(1.0, 5, -1.0, False)],\n",
       "   1: [(1.0, 6, -1.0, False)],\n",
       "   2: [(1.0, 17, -1.0, False)],\n",
       "   3: [(1.0, 4, -1.0, False)]},\n",
       "  6: {0: [(1.0, 6, -1.0, False)],\n",
       "   1: [(1.0, 7, -1.0, False)],\n",
       "   2: [(1.0, 18, -1.0, False)],\n",
       "   3: [(1.0, 5, -1.0, False)]},\n",
       "  7: {0: [(1.0, 7, -1.0, False)],\n",
       "   1: [(1.0, 8, -1.0, False)],\n",
       "   2: [(1.0, 19, -1.0, False)],\n",
       "   3: [(1.0, 6, -1.0, False)]},\n",
       "  8: {0: [(1.0, 8, -1.0, False)],\n",
       "   1: [(1.0, 9, -1.0, False)],\n",
       "   2: [(1.0, 20, -1.0, False)],\n",
       "   3: [(1.0, 7, -1.0, False)]},\n",
       "  9: {0: [(1.0, 9, -1.0, False)],\n",
       "   1: [(1.0, 10, -1.0, False)],\n",
       "   2: [(1.0, 21, -1.0, False)],\n",
       "   3: [(1.0, 8, -1.0, False)]},\n",
       "  10: {0: [(1.0, 10, -1.0, False)],\n",
       "   1: [(1.0, 11, -1.0, False)],\n",
       "   2: [(1.0, 22, -1.0, False)],\n",
       "   3: [(1.0, 9, -1.0, False)]},\n",
       "  11: {0: [(1.0, 11, -1.0, False)],\n",
       "   1: [(1.0, 11, -1.0, False)],\n",
       "   2: [(1.0, 23, -1.0, False)],\n",
       "   3: [(1.0, 10, -1.0, False)]},\n",
       "  12: {0: [(1.0, 0, -1.0, False)],\n",
       "   1: [(1.0, 13, -1.0, False)],\n",
       "   2: [(1.0, 24, -1.0, False)],\n",
       "   3: [(1.0, 12, -1.0, False)]},\n",
       "  13: {0: [(1.0, 1, -1.0, False)],\n",
       "   1: [(1.0, 14, -1.0, False)],\n",
       "   2: [(1.0, 25, -1.0, False)],\n",
       "   3: [(1.0, 12, -1.0, False)]},\n",
       "  14: {0: [(1.0, 2, -1.0, False)],\n",
       "   1: [(1.0, 15, -1.0, False)],\n",
       "   2: [(1.0, 26, -1.0, False)],\n",
       "   3: [(1.0, 13, -1.0, False)]},\n",
       "  15: {0: [(1.0, 3, -1.0, False)],\n",
       "   1: [(1.0, 16, -1.0, False)],\n",
       "   2: [(1.0, 27, -1.0, False)],\n",
       "   3: [(1.0, 14, -1.0, False)]},\n",
       "  16: {0: [(1.0, 4, -1.0, False)],\n",
       "   1: [(1.0, 17, -1.0, False)],\n",
       "   2: [(1.0, 28, -1.0, False)],\n",
       "   3: [(1.0, 15, -1.0, False)]},\n",
       "  17: {0: [(1.0, 5, -1.0, False)],\n",
       "   1: [(1.0, 18, -1.0, False)],\n",
       "   2: [(1.0, 29, -1.0, False)],\n",
       "   3: [(1.0, 16, -1.0, False)]},\n",
       "  18: {0: [(1.0, 6, -1.0, False)],\n",
       "   1: [(1.0, 19, -1.0, False)],\n",
       "   2: [(1.0, 30, -1.0, False)],\n",
       "   3: [(1.0, 17, -1.0, False)]},\n",
       "  19: {0: [(1.0, 7, -1.0, False)],\n",
       "   1: [(1.0, 20, -1.0, False)],\n",
       "   2: [(1.0, 31, -1.0, False)],\n",
       "   3: [(1.0, 18, -1.0, False)]},\n",
       "  20: {0: [(1.0, 8, -1.0, False)],\n",
       "   1: [(1.0, 21, -1.0, False)],\n",
       "   2: [(1.0, 32, -1.0, False)],\n",
       "   3: [(1.0, 19, -1.0, False)]},\n",
       "  21: {0: [(1.0, 9, -1.0, False)],\n",
       "   1: [(1.0, 22, -1.0, False)],\n",
       "   2: [(1.0, 33, -1.0, False)],\n",
       "   3: [(1.0, 20, -1.0, False)]},\n",
       "  22: {0: [(1.0, 10, -1.0, False)],\n",
       "   1: [(1.0, 23, -1.0, False)],\n",
       "   2: [(1.0, 34, -1.0, False)],\n",
       "   3: [(1.0, 21, -1.0, False)]},\n",
       "  23: {0: [(1.0, 11, -1.0, False)],\n",
       "   1: [(1.0, 23, -1.0, False)],\n",
       "   2: [(1.0, 35, -1.0, False)],\n",
       "   3: [(1.0, 22, -1.0, False)]},\n",
       "  24: {0: [(1.0, 12, -1.0, False)],\n",
       "   1: [(1.0, 25, -1.0, False)],\n",
       "   2: [(1.0, 36, -1.0, False)],\n",
       "   3: [(1.0, 24, -1.0, False)]},\n",
       "  25: {0: [(1.0, 13, -1.0, False)],\n",
       "   1: [(1.0, 26, -1.0, False)],\n",
       "   2: [(1.0, 37, -100.0, True)],\n",
       "   3: [(1.0, 24, -1.0, False)]},\n",
       "  26: {0: [(1.0, 14, -1.0, False)],\n",
       "   1: [(1.0, 27, -1.0, False)],\n",
       "   2: [(1.0, 38, -100.0, True)],\n",
       "   3: [(1.0, 25, -1.0, False)]},\n",
       "  27: {0: [(1.0, 15, -1.0, False)],\n",
       "   1: [(1.0, 28, -1.0, False)],\n",
       "   2: [(1.0, 39, -100.0, True)],\n",
       "   3: [(1.0, 26, -1.0, False)]},\n",
       "  28: {0: [(1.0, 16, -1.0, False)],\n",
       "   1: [(1.0, 29, -1.0, False)],\n",
       "   2: [(1.0, 40, -100.0, True)],\n",
       "   3: [(1.0, 27, -1.0, False)]},\n",
       "  29: {0: [(1.0, 17, -1.0, False)],\n",
       "   1: [(1.0, 30, -1.0, False)],\n",
       "   2: [(1.0, 41, -100.0, True)],\n",
       "   3: [(1.0, 28, -1.0, False)]},\n",
       "  30: {0: [(1.0, 18, -1.0, False)],\n",
       "   1: [(1.0, 31, -1.0, False)],\n",
       "   2: [(1.0, 42, -100.0, True)],\n",
       "   3: [(1.0, 29, -1.0, False)]},\n",
       "  31: {0: [(1.0, 19, -1.0, False)],\n",
       "   1: [(1.0, 32, -1.0, False)],\n",
       "   2: [(1.0, 43, -100.0, True)],\n",
       "   3: [(1.0, 30, -1.0, False)]},\n",
       "  32: {0: [(1.0, 20, -1.0, False)],\n",
       "   1: [(1.0, 33, -1.0, False)],\n",
       "   2: [(1.0, 44, -100.0, True)],\n",
       "   3: [(1.0, 31, -1.0, False)]},\n",
       "  33: {0: [(1.0, 21, -1.0, False)],\n",
       "   1: [(1.0, 34, -1.0, False)],\n",
       "   2: [(1.0, 45, -100.0, True)],\n",
       "   3: [(1.0, 32, -1.0, False)]},\n",
       "  34: {0: [(1.0, 22, -1.0, False)],\n",
       "   1: [(1.0, 35, -1.0, False)],\n",
       "   2: [(1.0, 46, -100.0, True)],\n",
       "   3: [(1.0, 33, -1.0, False)]},\n",
       "  35: {0: [(1.0, 23, -1.0, False)],\n",
       "   1: [(1.0, 35, -1.0, False)],\n",
       "   2: [(1.0, 47, -1.0, True)],\n",
       "   3: [(1.0, 34, -1.0, False)]},\n",
       "  36: {0: [(1.0, 24, -1.0, False)],\n",
       "   1: [(1.0, 37, -100.0, True)],\n",
       "   2: [(1.0, 36, -1.0, False)],\n",
       "   3: [(1.0, 36, -1.0, False)]},\n",
       "  37: {0: [(1.0, 25, -1.0, False)],\n",
       "   1: [(1.0, 38, -100.0, True)],\n",
       "   2: [(1.0, 37, -100.0, True)],\n",
       "   3: [(1.0, 36, -1.0, False)]},\n",
       "  38: {0: [(1.0, 26, -1.0, False)],\n",
       "   1: [(1.0, 39, -100.0, True)],\n",
       "   2: [(1.0, 38, -100.0, True)],\n",
       "   3: [(1.0, 37, -100.0, True)]},\n",
       "  39: {0: [(1.0, 27, -1.0, False)],\n",
       "   1: [(1.0, 40, -100.0, True)],\n",
       "   2: [(1.0, 39, -100.0, True)],\n",
       "   3: [(1.0, 38, -100.0, True)]},\n",
       "  40: {0: [(1.0, 28, -1.0, False)],\n",
       "   1: [(1.0, 41, -100.0, True)],\n",
       "   2: [(1.0, 40, -100.0, True)],\n",
       "   3: [(1.0, 39, -100.0, True)]},\n",
       "  41: {0: [(1.0, 29, -1.0, False)],\n",
       "   1: [(1.0, 42, -100.0, True)],\n",
       "   2: [(1.0, 41, -100.0, True)],\n",
       "   3: [(1.0, 40, -100.0, True)]},\n",
       "  42: {0: [(1.0, 30, -1.0, False)],\n",
       "   1: [(1.0, 43, -100.0, True)],\n",
       "   2: [(1.0, 42, -100.0, True)],\n",
       "   3: [(1.0, 41, -100.0, True)]},\n",
       "  43: {0: [(1.0, 31, -1.0, False)],\n",
       "   1: [(1.0, 44, -100.0, True)],\n",
       "   2: [(1.0, 43, -100.0, True)],\n",
       "   3: [(1.0, 42, -100.0, True)]},\n",
       "  44: {0: [(1.0, 32, -1.0, False)],\n",
       "   1: [(1.0, 45, -100.0, True)],\n",
       "   2: [(1.0, 44, -100.0, True)],\n",
       "   3: [(1.0, 43, -100.0, True)]},\n",
       "  45: {0: [(1.0, 33, -1.0, False)],\n",
       "   1: [(1.0, 46, -100.0, True)],\n",
       "   2: [(1.0, 45, -100.0, True)],\n",
       "   3: [(1.0, 44, -100.0, True)]},\n",
       "  46: {0: [(1.0, 34, -1.0, False)],\n",
       "   1: [(1.0, 47, -1.0, True)],\n",
       "   2: [(1.0, 46, -100.0, True)],\n",
       "   3: [(1.0, 45, -100.0, True)]},\n",
       "  47: {0: [(1.0, 35, -1.0, False)],\n",
       "   1: [(1.0, 47, -1.0, True)],\n",
       "   2: [(1.0, 47, -1.0, True)],\n",
       "   3: [(1.0, 46, -100.0, True)]}},\n",
       " '_cliff': array([[False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False],\n",
       "        [False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True, False]], dtype=bool),\n",
       " '_closed': False,\n",
       " '_env_closer_id': 1,\n",
       " '_spec': None,\n",
       " 'action_space': Discrete(4),\n",
       " 'isd': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       " 'lastaction': None,\n",
       " 'nA': 4,\n",
       " 'nS': 48,\n",
       " 'np_random': <mtrand.RandomState at 0x18501853ca8>,\n",
       " 'observation_space': Discrete(48),\n",
       " 's': 36,\n",
       " 'shape': (4, 12)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = CliffWalkingEnv()\n",
    "env.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PolicyEstimator():\n",
    "    \"\"\"\n",
    "    Policy Function approximator.\n",
    "    \n",
    "    A policy estimator is a function that produce the following distribution\n",
    "    π(a|s, θ)\n",
    "    \n",
    "    s is the current state\n",
    "    a is an action corresponding \n",
    "    θ is the set of parameters, in this case, it is a neural network\n",
    "    \n",
    "    Each time, we have two inputs:\n",
    "        - A state generated by Monte Carlo\n",
    "        - An action generated by Monte Carlo\n",
    "    The model would produce (from the state) an output layer\n",
    "    that correspond to a preference function h(s,a).\n",
    "    \n",
    "    Following is the formula for updating:\n",
    "    \n",
    "    θ += α*γ^t*G * DELTA_θ (log π(At|St, θ))\n",
    "    \n",
    "    or, more succintly, for baseline also:\n",
    "    \n",
    "    θ += α * TARGET_WEIGHT * DELTA_θ (log π(At|St, θ))\n",
    "    \n",
    "    where TARGET_WEIGHT could be the (discounted) return from time t\n",
    "    adjusted with baseline.\n",
    "    \n",
    "    This corresponding to the following graph mechanism:\n",
    "    \n",
    "    The graph basically predict the policy action\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate=0.01, scope=\"policy_estimator\"):\n",
    "        \"\"\"\n",
    "        The code to declare your tensorflow graph comes here\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(scope): \n",
    "            \"Declare all placeholders\"\n",
    "            \"Placeholder for input\"\n",
    "            \"\"\"\n",
    "            Now in this case, if the state is represented as a number ranking from\n",
    "            start point of the map to the end, we lost the locality between\n",
    "            cells of two consecutive rows.\n",
    "            So let's make it a row and column\n",
    "            \"\"\"\n",
    "            # No batch\n",
    "            self.state = tf.placeholder([2], name=\"state\", dtype = tf.int32)\n",
    "            \n",
    "            \"Placeholder for Monte Carlo action\"\n",
    "            self.action = tf.placeholder(name=\"action\", dtype = tf.int32)\n",
    "            \n",
    "            \"Placeholder for target\"\n",
    "            self.target = tf.placeholder(name=\"target\", dtype = tf.int32)\n",
    "            \n",
    "            \"Placeholder for action\"\n",
    "            \n",
    "            \"Declare all nodes in the graph\"\n",
    "    \n",
    "    def predict(self, state, sess=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def update(self, state, target, action, sess=None):\n",
    "        \"\"\"\n",
    "        state: input state\n",
    "        target: final return of an episode\n",
    "        action: input action\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ValueEstimator():\n",
    "    \"\"\"\n",
    "    Value Function approximator. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate=0.1, scope=\"value_estimator\"):\n",
    "        \"\"\"\n",
    "        \"\"\"       \n",
    "    \n",
    "    def predict(self, state, sess=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "\n",
    "    def update(self, state, target, sess=None):\n",
    "        \"\"\"\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reinforce(env, estimator_policy, estimator_value, num_episodes, discount_factor=1.0):\n",
    "    \"\"\"\n",
    "    REINFORCE (Monte Carlo Policy Gradient) Algorithm. Optimizes the policy\n",
    "    function approximator using policy gradient.\n",
    "    \n",
    "    Args:\n",
    "        env: OpenAI environment.\n",
    "        estimator_policy: Policy Function to be optimized \n",
    "        estimator_value: Value function approximator, used as a baseline\n",
    "        num_episodes: Number of episodes to run for\n",
    "        discount_factor: Time-discount factor\n",
    "    \n",
    "    Returns:\n",
    "        An EpisodeStats object with two numpy arrays for episode_lengths and episode_rewards.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "policy_estimator = PolicyEstimator()\n",
    "value_estimator = ValueEstimator()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Note, due to randomness in the policy the number of episodes you need to learn a good\n",
    "    # policy may vary. ~2000-5000 seemed to work well for me.\n",
    "    stats = reinforce(env, policy_estimator, value_estimator, 2000, discount_factor=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
