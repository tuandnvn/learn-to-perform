{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import gym\n",
    "from gym import error, spaces\n",
    "from gym import utils\n",
    "from gym.utils import seeding\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from simulator.utils import Cube2D, Transform2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Gaussian(gym.Space):\n",
    "    \"\"\"\n",
    "    A Gaussian space randomizes an action as a datapoint\n",
    "    using a location and a covariance.\n",
    "    \n",
    "    This is actually a multivariate normal distribution (MVN),\n",
    "    but with non-correlated variables \n",
    "    (the covariance matrix is diagonal and positive)\n",
    "    \n",
    "    A sample usage:\n",
    "    self.action_space = Gaussian(location = [-1,2], diagonal_cov = [1,1])\n",
    "    \"\"\"\n",
    "    def __init__(self, location, diagonal_cov, n_objects = 2, shape=None):\n",
    "        \"\"\"\n",
    "        Two kinds of valid inputs\n",
    "        \n",
    "        - location and diagonal_cov are scalar -> Gaussian distribution\n",
    "        - location and diagonal_cov are np array of same size\n",
    "        \"\"\"\n",
    "        self.n_objects = n_objects\n",
    "        \n",
    "        if np.isscalar(location) and np.isscalar(diagonal_cov):\n",
    "            \"\"\"Gaussian distribution\"\"\"\n",
    "            self.location = np.array([location])\n",
    "            self.diagonal_cov = np.array([diagonal_cov])\n",
    "            self.shape = (1,)\n",
    "        elif isinstance(location, list) and isinstance(diagonal_cov, list):\n",
    "            assert len(location) == len(diagonal_cov)\n",
    "            \n",
    "            self.location = np.array(location)\n",
    "            self.diagonal_cov = np.diag(diagonal_cov)\n",
    "            \n",
    "            self.shape = self.location.shape\n",
    "        else:\n",
    "            assert isinstance(location, np.ndarray)\n",
    "            assert isinstance(diagonal_cov, np.ndarray)\n",
    "            assert location.shape == diagonal_cov.shape\n",
    "        \n",
    "            self.shape = location.shape\n",
    "            \n",
    "            self.location = np.flatten(location)\n",
    "            self.diagonal_cov = np.diag(np.flatten(diagonal_cov))\n",
    "            \n",
    "    def sample(self, object_index = None):\n",
    "        \"\"\"\n",
    "        sample an action to take:\n",
    "        \n",
    "        if object_index == None:\n",
    "            sample both object_index and location of final point\n",
    "        else:\n",
    "            sample jus the location of final point\n",
    "        \"\"\"\n",
    "        s = np.random.multivariate_normal(self.location, self.diagonal_cov)\n",
    "        \n",
    "        # Reshape to original \n",
    "        s.shape = self.shape\n",
    "        \n",
    "        if object_index:\n",
    "            return (object_index, s)\n",
    "        else:\n",
    "            object_index = np.random.choice(self.n_objects)\n",
    "            return (object_index, s)\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return \"MVN (location= \" + str(self.location) + \"; variances = \" + str(self.diagonal_cov) +\")\"\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return np.allclose(self.location, other.location) and \\\n",
    "                np.allclose(self.diagonal_cov, other.diagonal_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Uniform(gym.Space):\n",
    "    \"\"\"\n",
    "    A uniform distributioin in a bounded \n",
    "    N-dimensional cube\n",
    "    \n",
    "    A sample usage:\n",
    "    Create a square (-1,-1), (-1,1), (1,1), (1,-1)\n",
    "    self.state_space = Uniform(p = [-1,-1], dimension = [2,2])\n",
    "    \"\"\"\n",
    "    def __init__(self, p, dimension, randomizer = np.random):\n",
    "        self.p = np.array(p)\n",
    "        self.dimension = np.array(dimension)\n",
    "        self.p_opposite = self.p + self.dimension\n",
    "        self.randomizer = randomizer\n",
    "        \n",
    "    def sample(self):\n",
    "        return self.randomizer.uniform(self.p, self.p_opposite)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Uniform (p= \" + str(self.p) + \"; dimension = \" + str(self.dimension) +\")\"\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return np.allclose(self.p, other.p) and \\\n",
    "                np.allclose(self.dimension, other.dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_lines(shape):\n",
    "    lines = []\n",
    "    for i in range(len(shape)):\n",
    "        j = (i + 1) % len(shape)\n",
    "        lines.append( [ shape[i], shape[j] ] )\n",
    "    \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pylab as pl\n",
    "from matplotlib import collections as mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors = [ (1, 0, 0, 1), (0,1,0,1), (0,0,1,1) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from simulator.simulator2d import Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BlockMovementEnv(gym.Env):\n",
    "    reward_range = (0, 1)\n",
    "    metadata = {'render.modes': ['human']}\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, target, playground_x = [-1,-1, 0],\n",
    "                 playground_dim = [2, 2, np.pi/2], name=None, n_objects = 2,\n",
    "                block_size = 0.15, \n",
    "                 progress_threshold = 0.9):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - name: the name of the event action to be learned\n",
    "        - target: is a function that produces\n",
    "        a value between 0 and 1 (event progress function)\n",
    "        - playground: a rectangle (x, y, rot, width, height, rot_range)\n",
    "        where (x,y) is a corner of the rectangle\n",
    "        - block_size: the default size for a block\n",
    "        - n_objects: number of objects to be randomized\n",
    "        - progress_threshold: condition for an episode to end\n",
    "        \n",
    "        **Note**\n",
    "        target_function:\n",
    "        event progress function will be defined based on the event type \n",
    "        currently learned\n",
    "        \n",
    "        target_function would be an LSTM\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        # This env is just a wrapper around an environment that \n",
    "        # I have created before\n",
    "        self.e = Environment()\n",
    "        self.target = target\n",
    "        self.n_objects = n_objects\n",
    "        self.playground_x = playground_x\n",
    "        self.playground_dim = playground_dim\n",
    "        self.name = name\n",
    "        self.block_size = block_size\n",
    "        \n",
    "        # Action space is dynamically created\n",
    "        # The action space would be a combination of a \n",
    "        self.action_space = None\n",
    "        # observation space is a subset of multiple object spaces\n",
    "        self.observation_space = None \n",
    "        \n",
    "        self._seed()\n",
    "        \n",
    "        self.object_space = Uniform(p = playground_x, \n",
    "                                         dimension = playground_dim, \n",
    "                                         randomizer = self.np_random)\n",
    "        \n",
    "        \n",
    "        self._reset()\n",
    "        \n",
    "    def _step(self, action):\n",
    "        # action is generated from the action_policy (external to the environment)\n",
    "        object_index, position = action\n",
    "        \n",
    "        self.s[object_index] = self.s[object_index] + position\n",
    "        self.lastaction = action\n",
    "        \n",
    "        \n",
    "        current_progress = self.target.predict()\n",
    "        \n",
    "        return (self.s)\n",
    "    \n",
    "    def _reset(self):\n",
    "        self.s = []\n",
    "        # states would be a list of location/orientation for block\n",
    "        # sampled from the observation space\n",
    "        for i in range(self.n_objects):\n",
    "            state = self.object_space.sample()\n",
    "            self.s.append(state)\n",
    "        \n",
    "        self.lastaction=None\n",
    "        return self.s\n",
    "\n",
    "    def _render(self, mode='human', close=False):\n",
    "        if close:\n",
    "            return\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_xticks(np.arange(self.playground_x[0], \n",
    "                                self.playground_x[0] + self.playground_dim[0], 0.1))\n",
    "        ax.set_yticks(np.arange(self.playground_x[1], \n",
    "                                self.playground_x[1] + self.playground_dim[1], 0.1))\n",
    "        ax.set_xlim([self.playground_x[0], \n",
    "                     self.playground_x[0] + self.playground_dim[0]])\n",
    "        ax.set_ylim([self.playground_x[1], \n",
    "                     self.playground_x[1] + self.playground_dim[1]])\n",
    "        fig.set_size_inches(20, 12)\n",
    "        \n",
    "        for i in range(self.n_objects):\n",
    "            # Obj is action position and rotation of object\n",
    "            obj = self.s[i]\n",
    "            position = obj[:2]\n",
    "            rotation = obj[2]\n",
    "            scale = self.block_size / 2\n",
    "            \n",
    "            c = Cube2D(transform = Transform2D(position, rotation, scale))\n",
    "            \n",
    "            shape = c.get_markers()\n",
    "            \n",
    "            lines = make_lines(shape)\n",
    "            lc = mc.LineCollection(lines, colors=colors[i], linewidths=2)\n",
    "            ax.add_collection(lc)\n",
    "        \n",
    "        ax.autoscale()\n",
    "        ax.margins(0.1)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def _seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = BlockMovementEnv(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABI0AAAKvCAYAAADnfD8zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSVKZ/w/GQRTQY1y3wQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x270eee92fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ProgressConfig(object):\n",
    "    s2s = False\n",
    "\n",
    "class EventProgressEstimator(object):\n",
    "    \"\"\"\n",
    "    Estimate the progress of event using LSTM\n",
    "    \"\"\"\n",
    "    def __init__(self, is_training, name=None, config = ProgressConfig()):\n",
    "        self.num_steps = num_steps = config.num_steps\n",
    "        self.n_input = n_input = config.n_input\n",
    "        self.size = size = config.hidden_size\n",
    "        # This is an option, if self.s2s = True -> Use all progress values\n",
    "        # otherwise just use the last progress value\n",
    "        self.s2s = config.s2s \n",
    "        \n",
    "        with tf.variable_scope(name):\n",
    "            \"Declare all placeholders\"\n",
    "            \"Placeholder for input\"\n",
    "            \n",
    "            \"\"\"\n",
    "            batch_size\n",
    "            num_steps: length of sequence\n",
    "            n_input: size of feature vectors\n",
    "            \"\"\"\n",
    "            self._input_data = tf.placeholder(tf.float32, [None, num_steps, n_input])\n",
    "            \n",
    "            \"\"\"\n",
    "            (batch_size x num_steps) for sequence to sequence\n",
    "            batch_size for \n",
    "            \"\"\"\n",
    "            if self.s2s:\n",
    "                self._targets = tf.placeholder(tf.float32, [None, num_steps])\n",
    "            else:\n",
    "                self._targets = tf.placeholder(tf.float32, [None])\n",
    "            \n",
    "            lstm_cell = BasicLSTMCell(size, forget_bias = 1.0, state_is_tuple=True)\n",
    "            \n",
    "            if is_training and config.keep_prob < 1:\n",
    "                lstm_cell = DropoutWrapper(lstm_cell, output_keep_prob=config.keep_prob)\n",
    "                \n",
    "            multi_lstm_cell = MultiRNNCell([lstm_cell] * config.num_layers, state_is_tuple=True)\n",
    "            \n",
    "            # Initial states of the cells\n",
    "            # cell.state_size = config.num_layers * 2 * size\n",
    "            # Size = ( batch_size x cell.state_size )\n",
    "            \n",
    "            # We don't know the batch_size here, so don't need\n",
    "            # to specify initial_state\n",
    "            # self._initial_state = multi_lstm_cell.zero_state(batch_size, tf.float32)\n",
    "            \n",
    "            inputs = tf.reshape(self._input_data, [-1, n_input]) # (batch_size * num_steps, n_input)\n",
    "            \n",
    "            with tf.variable_scope(\"linear\"):\n",
    "                weight = tf.get_variable(\"weight\", [n_input, size])\n",
    "                bias = tf.get_variable(\"bias\", [size])\n",
    "\n",
    "                # (batch_size * num_steps, size)\n",
    "                inputs = tf.matmul(inputs, weight) + bias\n",
    "                \n",
    "            inputs = tf.reshape(inputs, (-1, num_steps, size)) # (batch_size, num_steps, size)\n",
    "            \n",
    "            # (output, state)\n",
    "            # output is of size:  ( batch_size, num_steps, size ) or (( batch_size, size ))\n",
    "            # state is of size:   ( batch_size, cell.state_size ) (last state only)\n",
    "            with tf.variable_scope(\"lstm\"):\n",
    "                output_and_state = tf.nn.dynamic_rnn(multi_lstm_cell, inputs, dtype=tf.float32)\n",
    "            \n",
    "            output = output_and_state[0]\n",
    "            # we will pass the hidden state to next run of lstm\n",
    "            self._final_state = output_and_state[1]\n",
    "            \n",
    "            with tf.variable_scope(\"output_linear\"):\n",
    "                weight = tf.get_variable(\"weight\", [size, 1])\n",
    "                bias = tf.get_variable(\"bias\", [1])\n",
    "\n",
    "                \n",
    "                if self.s2s:\n",
    "                    # Need to reshape to 2 dimensions\n",
    "                    output = tf.reshape(output, [-1, size])\n",
    "                    output = output @ weight + bias\n",
    "                    # ( batch_size, num_steps )  \n",
    "                    output = tf.reshape(output, [-1, num_steps])\n",
    "                else:\n",
    "                    #( batch_size, 1)\n",
    "                    # @ is the same as matmul\n",
    "                    output = output @ weight + bias\n",
    "                    \n",
    "            # Remove all 1 dimension\n",
    "            # ( batch_size, num_steps ) or (batch_size)\n",
    "            self.output = tf.squeeze(output)\n",
    "            \n",
    "            # Loss = mean squared error of target and predictions\n",
    "            self.loss = tf.losses.mean_squared_error(self._targets, output)\n",
    "            \n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "            \n",
    "            self.train_op = self.optimizer.minimize(\n",
    "                self.loss, global_step=tf.contrib.framework.get_global_step())\n",
    "    \n",
    "    def checkInputs(self, inputs):\n",
    "        assert isinstance(inputs, np.ndarray)\n",
    "        \n",
    "        assert len(inputs.shape) == 3\n",
    "        assert inputs.shape[1] == self.num_steps\n",
    "        assert inputs.shape[2] == self.n_input\n",
    "    \n",
    "    def checkOutputs(self, outputs, batch_size):\n",
    "        assert isinstance(outputs, np.ndarray)\n",
    "        if self.s2s:\n",
    "            assert len(outputs.shape) == 2\n",
    "            assert outputs[0] == batch_size\n",
    "            assert outputs[1] == self.num_steps\n",
    "        else:\n",
    "            assert len(outputs.shape) == 1\n",
    "            assert outputs[0] == batch_size\n",
    "            \n",
    "        \n",
    "    def update(self, inputs, outputs, sess=None):\n",
    "        \"\"\"\n",
    "        inputs: np.array (batch_size, num_steps, n_input)\n",
    "        outputs: np.array (batch_size, num_steps) or (batch_size)\n",
    "        \n",
    "        We need to run train_op to update the parameters\n",
    "        We also need to return its loss\n",
    "        \"\"\"\n",
    "        self.checkInputs(inputs)\n",
    "        \n",
    "        batch_size = inputs.shape[0]\n",
    "        \n",
    "        self.checkOutputs(outputs, batch_size)\n",
    "        \n",
    "        sess = sess or tf.get_default_session()\n",
    "        _, loss = sess.run([self.train_op, self.loss], \n",
    "                           {self._input_data: inputs, self._targets: outputs})\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def predict(self, inputs, outputs = None, sess=None):\n",
    "        \"\"\"\n",
    "        inputs: np.array (batch_size, num_steps, n_input)\n",
    "        outputs: np.array (batch_size, num_steps) or (batch_size)\n",
    "        \n",
    "        This function would not run train_op\n",
    "        outputs is only optional if we want to get the loss\n",
    "        \"\"\"\n",
    "        self.checkInputs(inputs)\n",
    "        \n",
    "        if outputs != None:\n",
    "            batch_size = inputs.shape[0]\n",
    "            self.checkOutputs(outputs, batch_size)\n",
    "        \n",
    "        sess = sess or tf.get_default_session()\n",
    "        \n",
    "        if outputs != None:\n",
    "            predicted, loss = sess.run([self.output, self.loss],\n",
    "                    {self._input_data: inputs, self._targets: outputs})\n",
    "            return (predicted, loss)\n",
    "        else:\n",
    "            predicted = sess.run(self.output,\n",
    "                    {self._input_data: inputs})\n",
    "            return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import DATA_DIR, FIRST_EXPERIMENT_CLASSES,\\\n",
    "    SESSION_NAME, SESSION_OBJECTS, SESSION_EVENTS, GLYPH_BOX, NORMAL, \\\n",
    "    START, END, LABEL\n",
    "from read_utils import load_one_param_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'findall'\n",
      "'NoneType' object has no attribute 'findall'\n"
     ]
    }
   ],
   "source": [
    "session_1 = load_one_param_file(os.path.join( DATA_DIR, 'SlideAround', 'Session1', 'files.param'))\n",
    "session_2 = load_one_param_file(os.path.join( DATA_DIR, 'SlideAround', 'Session2', 'files.param'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "qsr_lib_src = os.path.join(module_path, \"strands_qsr_lib\\qsr_lib\\src3\")\n",
    "\n",
    "sys.path.append(qsr_lib_src)\n",
    "\n",
    "from qsrlib.qsrlib import QSRlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path = ['', 'C:\\\\Anaconda3\\\\envs\\\\tensorflow-cpu\\\\python35.zip', 'C:\\\\Anaconda3\\\\envs\\\\tensorflow-cpu\\\\DLLs', 'C:\\\\Anaconda3\\\\envs\\\\tensorflow-cpu\\\\lib', 'C:\\\\Anaconda3\\\\envs\\\\tensorflow-cpu', 'C:\\\\Anaconda3\\\\envs\\\\tensorflow-cpu\\\\lib\\\\site-packages', 'C:\\\\Anaconda3\\\\envs\\\\tensorflow-cpu\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\Tuan Do\\\\.ipython', 'D:\\\\git\\\\learn-to-perform']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from qsrlib.qsrlib import QSRlib, QSRlib_Request_Message\n",
    "from qsrlib_io.world_trace import Object_State, World_Trace\n",
    "\n",
    "from feature.project_table import project_markers, estimate_cube_2d\n",
    "from utils import SESSION_OBJECTS, SESSION_LEN, BLOCK_SIZE, ROTATION_QUANTIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def qsr_feature_extractor ( qsrlib, object_data, object_1_name, object_2_name, session_len ):\n",
    "    '''\n",
    "    feature_selection between two objects\n",
    "    # of features = 13\n",
    "    \n",
    "    8 features here\n",
    "    (o1.position, o2.position) - cardir, cardir_diff, argd, argd_diff, qtccs 4 features\n",
    "\n",
    "    -- other features\n",
    "    \n",
    "    2 features\n",
    "    quantized rotation of two objects\n",
    "    1 feature\n",
    "    quantized rotation difference between two objects\n",
    "    2 features\n",
    "    quantized difference of rotations btw two frames of two objects\n",
    "    '''\n",
    "    object_1 = object_data[object_1_name]\n",
    "    object_2 = object_data[object_2_name]\n",
    "\n",
    "    o1 = [Object_State(name=\"o1\", timestamp=i, x=object_1[i].transform.position[0][0], y=object_1[i].transform.position[0][1]) \n",
    "            for i in range(session_len)]\n",
    "    o2 = [Object_State(name=\"o2\", timestamp=i, x=object_2[i].transform.position[0][0], y=object_2[i].transform.position[0][1]) \n",
    "            for i in range(session_len)]\n",
    "\n",
    "    world = World_Trace()\n",
    "    world.add_object_state_series(o1)\n",
    "    world.add_object_state_series(o2)\n",
    "\n",
    "    qsrlib_request_message = QSRlib_Request_Message(which_qsr=['cardir', 'argd', 'qtccs'], input_data=world, \n",
    "                    dynamic_args = {'cardir': {'qsrs_for': [('o1', 'o2')]},\n",
    "                                    'argd': {'qsrs_for': [('o1', 'o2')], \n",
    "                                            'qsr_relations_and_values' : dict((\"\" + str(i), i * BLOCK_SIZE / 2) for i in range(20)) },\n",
    "                                    'qtccs': {'qsrs_for': [('o1', 'o2')], \n",
    "                                              'quantisation_factor': 0.001, 'angle_quantisation_factor' : np.pi / 5,\n",
    "                                              'validate': False, 'no_collapse': True\n",
    "                                   }})\n",
    "\n",
    "    # Number of features that you calculate the difference between two consecutive frames\n",
    "    diff_feature = 2\n",
    "    try:\n",
    "        # pretty_print_world_qsr_trace(['cardir', 'mos', 'argd', 'qtccs'], qsrlib_response_message)\n",
    "        qsrlib_response_message = qsrlib.request_qsrs(req_msg=qsrlib_request_message)\n",
    "\n",
    "        # (#frame, 8)\n",
    "        qsr_feature = turn_response_to_features([('o1,o2')], qsrlib_response_message, diff_feature)\n",
    "\n",
    "        # rotation features\n",
    "        quantized_r_1 = np.array([object_1[i].transform.rotation // ROTATION_QUANTIZATION for i in range(session_len)])\n",
    "        quantized_r_2 = np.array([object_2[i].transform.rotation // ROTATION_QUANTIZATION for i in range(session_len)])\n",
    "        quantized_diff = quantized_r_1 - quantized_r_2\n",
    "        diff_quantized_r_1 = np.pad(np.ediff1d(quantized_r_1), (1,0), 'constant', constant_values = (0,))\n",
    "        diff_quantized_r_2 = np.pad(np.ediff1d(quantized_r_2), (1,0), 'constant', constant_values = (0,))\n",
    "\n",
    "        # column forms\n",
    "        quantized_r_1.shape = (session_len, 1)\n",
    "        quantized_r_2.shape = (session_len, 1)\n",
    "        quantized_diff.shape = (session_len, 1)\n",
    "        diff_quantized_r_1.shape = (session_len, 1)\n",
    "        diff_quantized_r_2.shape = (session_len, 1)\n",
    "\n",
    "        return np.concatenate([qsr_feature, quantized_r_1, quantized_r_2, quantized_diff, diff_quantized_r_1, diff_quantized_r_2], axis = 1)\n",
    "\n",
    "    except ValueError as e:\n",
    "        print (e)\n",
    "        print ('Problem in data of length ' + str(len_data))\n",
    "        return []\n",
    "\n",
    "cdid = dict( (u, i) for (i, u) in enumerate( ['n', 'nw', 'w', 'sw', 's', 'se', 'e', 'ne', 'eq'] ))\n",
    "mosd = dict( (u, i) for (i, u) in enumerate( ['s', 'm'] ))\n",
    "qtcc_relations = dict( (u, i) for (i, u) in enumerate( ['-', '0', '+'] ))\n",
    "\n",
    "def cardir_index ( cardir ):\n",
    "    return cdid [cardir]\n",
    "\n",
    "def mos_index ( mos ):\n",
    "    return mosd [mos]\n",
    "\n",
    "def qtcc_index ( qtcc_relation ):\n",
    "    return qtcc_relations [qtcc_relation] - 1\n",
    "\n",
    "'''\n",
    "diff_feature: number of features at the beginning that need to create difference between two frames\n",
    "all_feature: total number of features\n",
    "'''\n",
    "def turn_response_to_features(keys, qsrlib_response_message, diff_feature):\n",
    "    feature_chain = []\n",
    "    for t in qsrlib_response_message.qsrs.get_sorted_timestamps():\n",
    "        features = []\n",
    "        # print (qsrlib_response_message.qsrs.trace[t].qsrs.keys())\n",
    "        for k in keys:\n",
    "            if k in qsrlib_response_message.qsrs.trace[t].qsrs:\n",
    "                v = qsrlib_response_message.qsrs.trace[t].qsrs[k]\n",
    "                \n",
    "                if 'cardir' in v.qsr:\n",
    "                    f = v.qsr['cardir']\n",
    "                    features.append(cardir_index(f))\n",
    "                if 'argd' in v.qsr:\n",
    "                    f = int( v.qsr['argd'] )\n",
    "                    features.append(f)\n",
    "        # Just to separate qtccs at the end of feature vectors\n",
    "        \n",
    "        for k in keys:\n",
    "            if k in qsrlib_response_message.qsrs.trace[t].qsrs:\n",
    "                v = qsrlib_response_message.qsrs.trace[t].qsrs[k]\n",
    "                if 'qtccs' in v.qsr:\n",
    "                    fs = v.qsr['qtccs']\n",
    "                    features += [qtcc_index(f) for f  in fs.split(',')]\n",
    "        \n",
    "        # print features\n",
    "        feature_chain.append(features)\n",
    "    \n",
    "    if len(feature_chain) == 0:\n",
    "        return feature_chain\n",
    "\n",
    "    # The first frame doesn't has qtcc relations\n",
    "    feature_chain[0] += [0 for i in range(4)]\n",
    "\n",
    "    feature_chain = np.array(feature_chain)\n",
    "    \n",
    "    print (feature_chain.shape)\n",
    "    # number of features\n",
    "    f_number = feature_chain.shape[1]\n",
    "\n",
    "    # Feature that need to calculate diff\n",
    "    # (#frame, diff_feature)\n",
    "    need_diff_chain = feature_chain[:, :diff_feature]\n",
    "\n",
    "    # Get the diff\n",
    "    # (#frame - 1, diff_feature)\n",
    "    diff_chain = np.diff(need_diff_chain, n=1, axis = 0)\n",
    "\n",
    "    # (#frame, diff_feature)\n",
    "    padded_diff_chain = np.pad(diff_chain, [(1,0), (0,0)], 'constant', constant_values = (0,))\n",
    "\n",
    "    \n",
    "    \n",
    "    # Add for the first frame\n",
    "    # (#frame, 2 * diff_feature + other_feature)\n",
    "    diff_feature_chain = np.concatenate ( [need_diff_chain, padded_diff_chain, feature_chain[:, diff_feature:]], axis = 1 )\n",
    "    \n",
    "    print ('shape of diff_feature_chain %s' % str(diff_feature_chain.shape))\n",
    "    return diff_feature_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from feature.project_table import project_markers, estimate_cube_2d\n",
    "from simulator.utils import Cube2D, Transform2D\n",
    "from matplotlib import pyplot as plt\n",
    "import bisect\n",
    "\n",
    "def count_finite( numpy_array ):\n",
    "    return np.sum( np.isfinite( numpy_array )) \n",
    "\n",
    "'''\n",
    "Area of polygons\n",
    "===========\n",
    "Params: numpy_array of size ( 3 x n )\n",
    "\n",
    "Return: object_data: Dictionary\n",
    "'''\n",
    "def area_dimension( numpy_array ):\n",
    "    s = np.reshape(numpy_array, (len(numpy_array)//3,3))\n",
    "    x = s[:,0]\n",
    "    y = s[:,1]\n",
    "    return 0.5*np.abs(np.dot(x,np.roll(y,1))-np.dot(y,np.roll(x,1)))\n",
    "\n",
    "def project_to2d_ ( session_data ):\n",
    "    object_data = {}\n",
    "\n",
    "    for object_name in session_data[SESSION_OBJECTS]:\n",
    "        if object_name == 'table':\n",
    "            polygon = []\n",
    "            for frameNo in session_data[SESSION_OBJECTS][object_name]:\n",
    "                frame_polygon = session_data[SESSION_OBJECTS][object_name][frameNo]\n",
    "\n",
    "            polygon.append(frame_polygon)\n",
    "\n",
    "            polygon = np.concatenate(polygon)\n",
    "            polygon = np.reshape(polygon, (len(polygon)//3, 3) )\n",
    "            \n",
    "            table_markers = polygon\n",
    "\n",
    "            # Just pick the first two points for coordination\n",
    "            first_point = table_markers[0]\n",
    "            second_point = table_markers[1]\n",
    "    \n",
    "    for object_name in session_data[SESSION_OBJECTS]:\n",
    "        if object_name != 'table':\n",
    "            object_data[object_name] = {}\n",
    "            for frameNo in session_data[SESSION_OBJECTS][object_name]:\n",
    "                frame_data = session_data[SESSION_OBJECTS][object_name][frameNo]\n",
    "\n",
    "                # Sort firstly by number of non-finite corners\n",
    "                # Sort secondly by size of marker (larger marker means better resolution)\n",
    "                # Size of marker should be only based on first two dimensions\n",
    "                # The third dimension might be very noisy\n",
    "                q = [((count_finite(frame_data[face_index]), area_dimension(frame_data[face_index]) ), face_index) \n",
    "                    for face_index in frame_data]\n",
    "                q = sorted(q, key = lambda t: t[0], reverse = True)\n",
    "\n",
    "                # Pick out the face_index with the most number of non-infinite values\n",
    "                best_face_index = q[0][1]\n",
    "                #print ('-----------')\n",
    "                #print (frame_data[best_face_index])\n",
    "                rectangle_projected = project_markers ( frame_data[best_face_index], table_markers )\n",
    "                #print (rectangle_projected)\n",
    "                object_data[object_name][int(frameNo)] = estimate_cube_2d ( rectangle_projected, first_point, second_point )\n",
    "\n",
    "    return object_data\n",
    "\n",
    "\n",
    "\n",
    "def interpolate_object_data( session_len, one_object_data ):\n",
    "    sorted_keys = sorted(one_object_data.keys())\n",
    "    for frame in range(session_len):\n",
    "        if frame not in one_object_data:\n",
    "            # missing frame\n",
    "            frame_position = bisect.bisect_left(sorted_keys, frame)\n",
    "\n",
    "            if frame_position == 0:\n",
    "                # missing at the beginning\n",
    "                one_object_data[frame] = one_object_data[sorted_keys[0]]\n",
    "            elif frame_position == len(sorted_keys):\n",
    "                # missing at the end\n",
    "                one_object_data[frame] = one_object_data[sorted_keys[-1]]\n",
    "            else:\n",
    "                pre_key = sorted_keys[frame_position - 1]\n",
    "                nex_key = sorted_keys[frame_position]\n",
    "                pre = one_object_data[pre_key].transform\n",
    "                nex = one_object_data[nex_key].transform\n",
    "                \n",
    "                p = (frame - pre_key)/(nex_key - pre_key)\n",
    "                q = (nex_key - frame)/(nex_key - pre_key)\n",
    "                transfrom = Transform2D ( nex.position * q + pre.position * p , \n",
    "                                         nex.rotation * q + pre.rotation * p, \n",
    "                                         nex.scale * q + pre.scale * p)\n",
    "                one_object_data[frame] = Cube2D( transfrom )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in float_scalars\n",
      "D:\\git\\learn-to-perform\\feature\\project_table.py:112: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n",
      "C:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\numpy\\linalg\\linalg.py:1804: RuntimeWarning: invalid value encountered in det\n",
      "  r = _umath_linalg.det(a, signature=signature)\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "You need at least 3 non-finite points to find a plane",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-140-bad147fc2d0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mobject_data_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproject_to2d_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mobject_data_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproject_to2d_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-139-0167a1e0fe2e>\u001b[0m in \u001b[0;36mproject_to2d_\u001b[1;34m(session_data)\u001b[0m\n\u001b[0;32m     62\u001b[0m                 \u001b[0mrectangle_projected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproject_markers\u001b[0m \u001b[1;33m(\u001b[0m \u001b[0mframe_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbest_face_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtable_markers\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m                 \u001b[1;31m#print (rectangle_projected)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m                 \u001b[0mobject_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mobject_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframeNo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimate_cube_2d\u001b[0m \u001b[1;33m(\u001b[0m \u001b[0mrectangle_projected\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst_point\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecond_point\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mobject_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\git\\learn-to-perform\\feature\\project_table.py\u001b[0m in \u001b[0;36mestimate_cube_2d\u001b[1;34m(rectangle_projected, first_point, second_point, block_size)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m     \u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m     \u001b[0mbottom_side_markers\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mCube2D\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mestimate\u001b[0m \u001b[0mlocations\u001b[0m \u001b[0mof\u001b[0m \u001b[0mrectangle_projected\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[1;36m2\u001b[0m\u001b[0md\u001b[0m \u001b[0mcoordination\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \"\"\"\n",
      "\u001b[1;32mD:\\git\\learn-to-perform\\feature\\project_table.py\u001b[0m in \u001b[0;36mestimate_plane\u001b[1;34m(points)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mfiltered_points\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpoints\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;31m#print ('filtered_points')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[1;31m#print (filtered_points)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_points\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You need at least 3 non-finite points to find a plane\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: You need at least 3 non-finite points to find a plane"
     ]
    }
   ],
   "source": [
    "qsrlib = QSRlib()\n",
    "\n",
    "object_data_1 = project_to2d_(session_1)\n",
    "object_data_2 = project_to2d_(session_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(object_data_1['Stella Artois'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_1 = qsr_feature_extractor(qsrlib, project_to2d_(session_1), 'Stella Artois', 'Shell', 2881)\n",
    "features_2 = qsr_feature_extractor(qsrlib, project_to2d_(session_2), 'Stella Artois', 'Shell', 2881)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
